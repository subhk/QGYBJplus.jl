#=
================================================================================
                            QGYBJ.jl - Main Module
================================================================================

This module implements the QG-YBJ+ (Quasi-Geostrophic Young-Ben Jelloul Plus)
model for simulating the interaction between near-inertial waves and balanced
ocean eddies.

PHYSICAL BACKGROUND:
--------------------
The QG-YBJ+ model couples two key physical processes:

1. BALANCED FLOW (Quasi-Geostrophic):
   - Governed by the QG potential vorticity (PV) equation
   - Represents mesoscale eddies and geostrophic currents
   - Evolves on the "slow" timescale

2. NEAR-INERTIAL WAVES (NIW):
   - Internal waves with frequencies near the Coriolis frequency f
   - Generated by wind forcing, tides, or other mechanisms
   - Evolves on the "fast" timescale but affects mean flow

KEY EQUATIONS:
--------------
The model solves two coupled equations:

(1) QG Potential Vorticity Evolution:
    ∂q/∂t + J(ψ, q) + J(ψ, qʷ) = dissipation

    where:
    - q = ∇²ψ + (f²/N²)∂²ψ/∂z² is the QG PV
    - ψ is the streamfunction (u = -∂ψ/∂y, v = ∂ψ/∂x)
    - qʷ is the wave feedback on mean flow (Xie & Vanneste 2015)
    - J(a,b) = ∂a/∂x ∂b/∂y - ∂a/∂y ∂b/∂x is the Jacobian

(2) YBJ+ Wave Envelope Evolution:
    ∂B/∂t + J(ψ, B) + B∂ζ/∂t = dispersion + refraction + dissipation

    where:
    - B = L⁺A is the wave envelope in YBJ+ form
    - A is the actual wave amplitude
    - ζ = ∇²ψ is the relative vorticity
    - L⁺ is an elliptic operator relating A and B

NUMERICAL METHODS:
------------------
- Pseudo-spectral in horizontal (FFT-based)
- Second-order finite differences in vertical
- Leapfrog time stepping with Robert-Asselin filter
- Tridiagonal solvers for elliptic inversions
- 2/3 dealiasing rule for nonlinear terms

REFERENCES:
-----------
- Asselin & Young (2019): YBJ+ formulation
- Xie & Vanneste (2015): Wave feedback qʷ
- Young & Ben Jelloul (1997): Original YBJ equation

CODE STRUCTURE:
---------------
- parameters.jl   : Model parameters (QGParams struct)
- grid.jl         : Spatial grid and spectral wavenumbers
- transforms.jl   : FFT planning (serial and parallel)
- physics.jl      : Stratification profiles, N², a_ell coefficients
- elliptic.jl     : Tridiagonal solvers for ψ and A inversions
- operators.jl    : Velocity computation from ψ
- nonlinear.jl    : Jacobians, refraction, wave feedback qʷ
- timestep.jl     : Time integration (Euler, Leapfrog)
- ybj_normal.jl   : Normal YBJ (non-plus) operators
- diagnostics.jl  : Energy diagnostics, omega equation
- model_interface.jl : High-level simulation API
- netcdf_io.jl    : NetCDF input/output
- particles/      : Lagrangian particle advection

GETTING STARTED:
----------------
    using QGYBJ

    # Create configuration
    config = create_simple_config(
        nx=64, ny=64, nz=64,
        dt=0.001, nt=1000,
        output_interval=100
    )

    # Run simulation
    result = run_simple_simulation(config)

================================================================================
=#

module QGYBJ

using LinearAlgebra

# External backends are optional. If you wish to use MPI/PencilArrays/PencilFFTs,
# load them in your environment before using QGYBJ. Serial mode works by default.
@info "MPI/PencilArrays/PencilFFTs not loaded yet. You can still use serial mode."

#=
================================================================================
                    MPI EXTENSION FUNCTION STUBS
================================================================================
These functions are implemented in ext/QGYBJMPIExt.jl when MPI, PencilArrays,
and PencilFFTs are loaded. They throw informative errors if called without
the required packages.

IMPORTANT: These stubs MUST be defined BEFORE the include statements below,
because the submodules use `using ..QGYBJ: transpose_to_z_pencil!, ...` to
import these functions during their compilation.
================================================================================
=#

const MPI_ERROR_MSG = """
MPI parallel functionality requires MPI.jl, PencilArrays.jl, and PencilFFTs.jl.
Install and load these packages first:

    using Pkg
    Pkg.add(["MPI", "PencilArrays", "PencilFFTs"])

    using MPI
    using PencilArrays
    using PencilFFTs
    using QGYBJ

    MPI.Init()
    mpi_config = QGYBJ.setup_mpi_environment()
"""

"""
    setup_mpi_environment(; topology=nothing)

Initialize MPI and return configuration for parallel execution.

Requires MPI.jl, PencilArrays.jl, and PencilFFTs.jl to be loaded.
Uses 2D pencil decomposition for optimal scalability.

# Keyword Arguments
- `topology`: Optional tuple (px, py) for process grid. If not specified,
  computed automatically to be as square as possible.

# Example
```julia
using MPI, PencilArrays, PencilFFTs, QGYBJ
MPI.Init()
mpi_config = setup_mpi_environment()
```
"""
function setup_mpi_environment(; kwargs...)
    error(MPI_ERROR_MSG)
end

"""
    init_mpi_grid(params::QGParams, mpi_config)

Initialize a Grid with MPI-distributed arrays using 2D PencilArrays decomposition.

# Arguments
- `params`: Model parameters
- `mpi_config`: MPI configuration from `setup_mpi_environment()`

# Returns
Grid with distributed arrays in xy-pencil configuration.
"""
function init_mpi_grid(params, mpi_config)
    error(MPI_ERROR_MSG)
end

"""
    init_mpi_state(grid, mpi_config; T=Float64)

Initialize a State with MPI-distributed PencilArrays.

All fields are allocated as PencilArrays using the grid's xy-pencil decomposition.
"""
function init_mpi_state(grid, mpi_config; kwargs...)
    error(MPI_ERROR_MSG)
end

"""
    plan_mpi_transforms(grid, mpi_config)

Create PencilFFTs plans for parallel 2D horizontal FFT execution.

Returns plans that handle transposes between pencil configurations automatically.
"""
function plan_mpi_transforms(grid, mpi_config)
    error(MPI_ERROR_MSG)
end

"""
    gather_to_root(arr, grid, mpi_config)

Gather a distributed PencilArray to the root process.

Returns the full array on rank 0, `nothing` on other ranks.
"""
function gather_to_root(arr, grid, mpi_config)
    error(MPI_ERROR_MSG)
end

"""
    scatter_from_root(arr, grid, mpi_config)

Scatter an array from root to all processes as PencilArrays.
"""
function scatter_from_root(arr, grid, mpi_config)
    error(MPI_ERROR_MSG)
end

"""
    mpi_barrier(mpi_config)

Synchronize all MPI processes.
"""
function mpi_barrier(mpi_config)
    error(MPI_ERROR_MSG)
end

"""
    mpi_reduce_sum(val, mpi_config)

Sum a value across all MPI processes using Allreduce.
"""
function mpi_reduce_sum(val, mpi_config)
    error(MPI_ERROR_MSG)
end

"""
    local_indices(grid)

Get the local index ranges for the current process.

In serial mode, returns full grid ranges. In MPI mode, returns
the local portion owned by this process (xy-pencil configuration).
"""
function local_indices(grid)
    # This one can work in serial mode - return full range
    if hasproperty(grid, :decomp) && grid.decomp === nothing
        return (1:grid.nx, 1:grid.ny, 1:grid.nz)
    elseif !hasproperty(grid, :decomp)
        return (1:grid.nx, 1:grid.ny, 1:grid.nz)
    end
    error(MPI_ERROR_MSG)
end

"""
    write_mpi_field(filename, varname, arr, grid, mpi_config)

Write a distributed field to file (gathers to root first).
"""
function write_mpi_field(filename, varname, arr, grid, mpi_config)
    error(MPI_ERROR_MSG)
end

"""
    init_mpi_random_field!(arr, grid, amplitude, seed_offset=0)

Initialize a PencilArray with deterministic random values.

Uses hash-based seeding to ensure reproducibility across different process counts.
"""
function init_mpi_random_field!(arr, grid, amplitude, seed_offset=0)
    error(MPI_ERROR_MSG)
end

"""
    init_mpi_workspace(grid, mpi_config; T=Float64)

Initialize workspace arrays for transpose operations.

Returns z-pencil arrays used for vertical operations (tridiagonal solves,
vertical derivatives).
"""
function init_mpi_workspace(grid, mpi_config; kwargs...)
    error(MPI_ERROR_MSG)
end

"""
    transpose_to_z_pencil!(dst, src, grid)

Transpose data from xy-pencil to z-pencil configuration.

After this operation, z is fully local on each process, enabling
vertical operations like tridiagonal solves and vertical derivatives.

In serial mode, this is a simple copy operation.
"""
function transpose_to_z_pencil!(dst, src, grid)
    # Serial mode - just copy
    if !hasproperty(grid, :decomp) || grid.decomp === nothing
        dst .= src
        return dst
    end
    error(MPI_ERROR_MSG)
end

"""
    transpose_to_xy_pencil!(dst, src, grid)

Transpose data from z-pencil to xy-pencil configuration.

Use this after vertical operations to return to the FFT-ready layout.

In serial mode, this is a simple copy operation.
"""
function transpose_to_xy_pencil!(dst, src, grid)
    # Serial mode - just copy
    if !hasproperty(grid, :decomp) || grid.decomp === nothing
        dst .= src
        return dst
    end
    error(MPI_ERROR_MSG)
end

"""
    get_local_range_xy(grid)

Get local index ranges for xy-pencil configuration (used for FFTs).

Returns a tuple of three UnitRanges: `(x_range, y_range, z_range)`.
In serial mode, returns full grid ranges.
"""
function get_local_range_xy(grid)
    if !hasproperty(grid, :decomp) || grid.decomp === nothing
        return (1:grid.nx, 1:grid.ny, 1:grid.nz)
    end
    error(MPI_ERROR_MSG)
end

"""
    get_local_range_z(grid)

Get local index ranges for z-pencil configuration (used for vertical operations).

Returns a tuple of three UnitRanges: `(x_range, y_range, z_range)`.
In serial mode, returns full grid ranges.
"""
function get_local_range_z(grid)
    if !hasproperty(grid, :decomp) || grid.decomp === nothing
        return (1:grid.nx, 1:grid.ny, 1:grid.nz)
    end
    error(MPI_ERROR_MSG)
end

"""
    local_to_global_xy(local_idx, dim, grid)

Convert local index to global index for xy-pencil configuration.

# Arguments
- `local_idx`: Local index on this process
- `dim`: Dimension (1=x, 2=y, 3=z)
- `grid`: Grid structure
"""
function local_to_global_xy(local_idx::Int, dim::Int, grid)
    if !hasproperty(grid, :decomp) || grid.decomp === nothing
        return local_idx
    end
    error(MPI_ERROR_MSG)
end

"""
    local_to_global_z(local_idx, dim, grid)

Convert local index to global index for z-pencil configuration.

# Arguments
- `local_idx`: Local index on this process
- `dim`: Dimension (1=x, 2=y, 3=z)
- `grid`: Grid structure
"""
function local_to_global_z(local_idx::Int, dim::Int, grid)
    if !hasproperty(grid, :decomp) || grid.decomp === nothing
        return local_idx
    end
    error(MPI_ERROR_MSG)
end

"""
    allocate_z_pencil(grid, T=ComplexF64)

Allocate an array in z-pencil configuration for vertical operations.

In z-pencil configuration, z is fully local on each process, enabling
vertical operations like tridiagonal solves.

In serial mode, returns a standard 3D array.
"""
function allocate_z_pencil(grid, ::Type{T}=ComplexF64) where T
    if !hasproperty(grid, :decomp) || grid.decomp === nothing
        return zeros(T, grid.nx, grid.ny, grid.nz)
    end
    error(MPI_ERROR_MSG)
end

"""
    allocate_xy_pencil(grid, T=ComplexF64)

Allocate an array in xy-pencil configuration for horizontal operations.

In xy-pencil configuration, data is ready for horizontal FFTs.

In serial mode, returns a standard 3D array.
"""
function allocate_xy_pencil(grid, ::Type{T}=ComplexF64) where T
    if !hasproperty(grid, :decomp) || grid.decomp === nothing
        return zeros(T, grid.nx, grid.ny, grid.nz)
    end
    error(MPI_ERROR_MSG)
end

#=
================================================================================
                              PUBLIC API EXPORTS
================================================================================
The exports are organized by functionality:

1. CORE DATA STRUCTURES:
   - QGParams: All model parameters (physics, numerics, switches)
   - Grid: Spatial grid and spectral wavenumbers
   - State: Prognostic (q, B) and diagnostic (ψ, A, u, v, w) fields

2. PHYSICS ROUTINES:
   - Elliptic solvers: invert_q_to_psi!, invert_B_to_A!, invert_helmholtz!
   - Nonlinear terms: jacobian_spectral!, convol_waqg!, refraction_waqg!, compute_qw!
   - Velocity operators: compute_velocities!, compute_vertical_velocity!

3. TIME STEPPING:
   - first_projection_step!: Forward Euler for initialization
   - leapfrog_step!: Main time integration with Robert-Asselin filter

4. HIGH-LEVEL INTERFACE:
   - QGYBJSimulation, setup_simulation, run_simulation!
   - Configuration builders: create_domain_config, create_model_config, etc.

5. I/O AND DIAGNOSTICS:
   - NetCDF output: ncdump_psi, ncdump_la, OutputManager
   - Energy diagnostics: wave_energy, flow_kinetic_energy
================================================================================
=#

# Public API - Core functionality
export QGParams, Grid, State,
       init_grid, init_state, init_pencil_decomposition!,
       plan_transforms!, setup_parallel_transforms, fft_forward!, fft_backward!,
       compute_wavenumbers!,
       # Local-to-global index mapping for PencilArrays compatibility
       get_local_range, local_to_global, get_kx, get_ky, get_kh2, get_local_dims, is_parallel_array,
       invert_q_to_psi!, compute_velocities!, compute_vertical_velocity!, compute_ybj_vertical_velocity!, compute_total_velocities!, compute_wave_velocities!,
       default_params, setup_model,
       a_ell_ut, dealias_mask,
       invert_B_to_A!, invert_helmholtz!,
       jacobian_spectral!, convol_waqg!, refraction_waqg!, compute_qw!, dissipation_q_nv!, int_factor,
       init_random_psi!,
        first_projection_step!, leapfrog_step!,
        sumB!, compute_sigma, compute_A!,
        omega_eqn_rhs!, wave_energy, flow_kinetic_energy, wave_energy_vavg, slice_horizontal, slice_vertical_xz

# Public API - New user interface
export DomainConfig, StratificationConfig, InitialConditionConfig, OutputConfig, ModelConfig,
       create_domain_config, create_stratification_config, create_initial_condition_config,
       create_output_config, create_model_config,
       QGYBJSimulation, setup_simulation, run_simulation!,
       create_simple_config, run_simple_simulation,
       OutputManager, write_state_file, read_initial_psi, read_initial_waves, read_stratification_profile,
       StratificationProfile, ConstantN, SkewedGaussian, TanhProfile,
       create_stratification_profile, compute_stratification_profile,
       # Legacy I/O compatibility functions (now implemented in netcdf_io.jl)
       ncdump_psi, ncdump_la, ncread_psi!, ncread_la!,
       # Parallel interface (legacy - prefer MPI extension)
       ParallelConfig, setup_parallel_environment, init_parallel_grid, init_parallel_state,
       # MPI extension interface (available when MPI/PencilArrays/PencilFFTs are loaded)
       setup_mpi_environment, init_mpi_grid, init_mpi_state, init_mpi_workspace, plan_mpi_transforms,
       gather_to_root, scatter_from_root, mpi_barrier, mpi_reduce_sum, local_indices,
       write_mpi_field, init_mpi_random_field!,
       # 2D decomposition transpose and allocation functions
       transpose_to_z_pencil!, transpose_to_xy_pencil!,
       get_local_range_xy, get_local_range_z, local_to_global_xy, local_to_global_z,
       allocate_z_pencil, allocate_xy_pencil,
       # Unified particle advection system (handles both serial and parallel automatically)
       ParticleConfig, ParticleState, ParticleTracker, create_particle_config,
       initialize_particles!, advect_particles!, interpolate_velocity_at_position,
       write_particle_trajectories, read_particle_trajectories, write_particle_snapshot,
       create_particle_output_file, write_particle_trajectories_by_zlevel,
       enable_auto_file_splitting!, finalize_trajectory_files!,
       # Advanced interpolation methods
       InterpolationMethod, TRILINEAR, TRICUBIC, ADAPTIVE, QUINTIC,
       # 3D particle distributions
       ParticleConfig3D, ParticleDistribution, create_particle_config_3d,
       initialize_particles_3d!, UNIFORM_GRID, LAYERED, RANDOM_3D, CUSTOM,
       create_uniform_3d_grid, create_layered_distribution, create_random_3d_distribution, create_custom_distribution

#=
================================================================================
                              MODULE INCLUDES
================================================================================
Files are included in dependency order. Each file is a self-contained module
that is "used" back into the main QGYBJ namespace.
================================================================================
=#

# Core data structures and parameters
include("parameters.jl")    # QGParams: all model parameters
include("grid.jl")          # Grid: spatial coordinates and wavenumbers

# FFT and spectral transforms
include("transforms.jl")    # FFTW planning, fft_forward!, fft_backward!

# Physics and numerical operators
include("physics.jl")       # Stratification N², a_ell coefficient
include("elliptic.jl")      # Tridiagonal solvers for elliptic inversions
include("operators.jl")     # Velocity computation from streamfunction

# Runtime utilities
include("runtime.jl")       # Setup helpers

# Nonlinear terms and tendencies
include("nonlinear.jl")     # Jacobians, refraction, wave feedback qʷ

# Time integration
include("timestep.jl")      # Forward Euler, Leapfrog with Robert-Asselin

# Initial conditions
include("initconds.jl")     # Random and analytic initial conditions

# Normal YBJ (non-plus) operators
include("ybj_normal.jl")    # sumB!, compute_sigma, compute_A! for normal YBJ

# Diagnostics
include("diagnostics.jl")   # Energy diagnostics, omega equation RHS

# Configuration and I/O (must be included before model_interface.jl)
include("config.jl")            # Configuration types (DomainConfig, etc.)
include("netcdf_io.jl")         # NetCDF I/O with legacy compatibility
include("initialization.jl")    # Field initialization helpers
include("stratification.jl")    # Stratification profiles
include("parallel_interface.jl") # Parallel configuration types

# High-level user interface (depends on the above)
include("model_interface.jl")   # QGYBJSimulation, run_simulation!, etc.

# Particle advection system (for Lagrangian tracking)
include("particles/unified_particle_advection.jl")  # Particle tracking core
include("particles/particle_io.jl")                  # Particle trajectory I/O

end # module
